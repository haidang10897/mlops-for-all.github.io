<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jongseob Jeon on</title><link>https://mlops-for-all.github.io/en/contributors/jongseob-jeon/</link><description>Recent content in Jongseob Jeon on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 24 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://mlops-for-all.github.io/en/contributors/jongseob-jeon/index.xml" rel="self" type="application/rss+xml"/><item><title>1. What is MLOps?</title><link>https://mlops-for-all.github.io/en/docs/introduction/intro/</link><pubDate>Fri, 03 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/introduction/intro/</guid><description>Machine Learning Project # 2012년 Alexnet 이후 CV, NLP를 비롯하여 데이터가 존재하는 도메인이라면 어디서든 머신러닝과 딥러닝을 도입하고자 하였습니다.
딥러닝과 머신러닝은 AI라는 단어로 묶이며 불렸고 많은 매체에서 AI의 필요성을 외쳤습니다. 그리고 무수히 많은 기업에서 머신러닝과 딥러닝을 이용한 수많은 프로젝트를 진행하였습니다. 하지만 그 결과는 어떻게 되었을까요?
엘리먼트 AI의 음병찬 동북아 지역 총괄책임자는 &amp;ldquo;10개 기업에 AI 프로젝트를 시작한다면 그중 9개는 컨셉검증(POC)만 하다 끝난다&amp;rdquo;고 말했습니다.
이처럼 많은 프로젝트에서 머신러닝과 딥러닝은 이 문제를 풀 수 있을 것 같다는 가능성만을 보여주고 사라졌습니다.</description></item><item><title>4.1. Install Kubernetes - K3s</title><link>https://mlops-for-all.github.io/en/docs/setup-kubernetes/kubernetes-with-k3s/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/setup-kubernetes/kubernetes-with-k3s/</guid><description>1. Prerequisite # 쿠버네티스 클러스터를 구축하기에 앞서, 필요한 구성 요소들을 클러스터에 설치합니다.
Install Prerequisite을 참고하여 Kubernetes를 설치하기 전에 필요한 요소들을 클러스터에 설치해 주시기 바랍니다.
k3s 에서는 기본값으로 containerd를 백엔드로 이용해 설치합니다. 하지만 저희는 GPU를 사용하기 위해서 docker를 백엔드로 사용해야 하므로 --docker 옵션을 통해 백엔드를 docker로 설치하겠습니다.
curl -sfL https://get.k3s.io | INSTALL_K3S_VERSION=v1.21.7+k3s1 sh -s - server --disable traefik --disable servicelb --disable local-storage --docker k3s를 설치 후 k3s config를 확인합니다
sudo cat /etc/rancher/k3s/k3s.</description></item><item><title>1. Kubeflow Introduction</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/kubeflow-intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/kubeflow-intro/</guid><description>Kubeflow를 사용하기 위해서는 컴포넌트(Component)와 파이프라인(Pipeline)을 작성해야 합니다.
모두의 MLOps에서 설명하는 방식은 Kubeflow Pipeline 공식 홈페이지에서 설명하는 방식과는 다소 차이가 있습니다. 여기에서는 Kubeflow Pipeline을 워크플로(Workflow)가 아닌 앞서 설명한 MLOps를 구성하는 요소 중 하나의 컴포넌트로 사용하기 때문입니다.
그럼 이제 컴포넌트와 파이프라인은 무엇이며 어떻게 작성할 수 있는지 알아보도록 하겠습니다.</description></item><item><title>2. Kubeflow Concepts</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/kubeflow-concepts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/kubeflow-concepts/</guid><description>Component # 컴포넌트(Component)는 컴포넌트 콘텐츠(Component contents)와 컴포넌트 래퍼(Component wrapper)로 구성되어 있습니다. 하나의 컴포넌트는 컴포넌트 래퍼를 통해 kubeflow에 전달되며 전달된 컴포넌트는 정의된 컴포넌트 콘텐츠를 실행(execute)하고 아티팩트(artifacts)들을 생산합니다.
Component Contents # 컴포넌트 콘텐츠를 구성하는 것은 총 3가지가 있습니다.
Environemnt Python code w\ Config Generates Artifacts 예시와 함께 각 구성 요소가 어떤 것인지 알아보도록 하겠습니다. 다음과 같이 데이터를 불러와 SVC(Support Vector Classifier)를 학습한 후 SVC 모델을 저장하는 과정을 적은 파이썬 코드가 있습니다.</description></item><item><title>3. Install Requirements</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/basic-requirements/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/basic-requirements/</guid><description>실습을 위해 권장하는 파이썬 버전은 python&amp;gt;=3.7입니다. 파이썬 환경에 익숙하지 않은 분들은 다음 Appendix 1. 파이썬 가상환경을 참고하여 클라이언트 노드에 설치해주신 뒤 패키지 설치를 진행해주시기를 바랍니다.
실습을 진행하기에서 필요한 패키지들과 버전은 다음과 같습니다.
requirements.txt
kfp==1.8.9 scikit-learn==1.0.1 mlflow==1.21.0 pandas==1.3.4 dill==0.3.4 앞에서 만든 파이썬 가상환경을 활성화합니다.
pyenv activate demo 패키지 설치를 진행합니다.
pip3 install -U pip pip3 install kfp==1.8.9 scikit-learn==1.0.1 mlflow==1.21.0 pandas==1.3.4 dill==0.3.4</description></item><item><title>4. Component - Write</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/basic-component/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/basic-component/</guid><description>Component # 컴포넌트(Component)를 작성하기 위해서는 다음과 같은 내용을 작성해야 합니다.
컴포넌트 콘텐츠(Component Contents) 작성 컴포넌트 래퍼(Component Wrapper) 작성 이제 각 과정에 대해서 알아보도록 하겠습니다.
Component Contents # 컴포넌트 콘텐츠는 우리가 흔히 작성하는 파이썬 코드와 다르지 않습니다.
예를 들어서 숫자를 입력으로 받고 입력받은 숫자를 출력한 뒤 반환하는 컴포넌트를 작성해 보겠습니다.
파이썬 코드로 작성하면 다음과 같이 작성할 수 있습니다.
print(number) 그런데 이 코드를 실행하면 에러가 나고 동작하지 않는데 그 이유는 출력해야 할 number가 정의되어 있지 않기 때문입니다.</description></item><item><title>5. Pipeline - Write</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/basic-pipeline/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/basic-pipeline/</guid><description>Pipeline # 컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행됩니다. 그러므로 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다. 그리고 파이프라인을 작성하기 위해서는 컴포넌트의 집합과 컴포넌트의 실행 순서가 필요합니다.
이번 페이지에서는 숫자를 입력받고 출력하는 컴포넌트와 두 개의 컴포넌트로부터 숫자를 받아서 합을 출력하는 컴포넌트가 있는 파이프라인을 만들어 보도록 하겠습니다.
Component Set # 우선 파이프라인에서 사용할 컴포넌트들을 작성합니다.
print_and_return_number 입력받은 숫자를 출력하고 반환하는 컴포넌트입니다.
컴포넌트가 입력받은 값을 반환하기 때문에 int를 return의 타입 힌트로 입력합니다.</description></item><item><title>6. Pipeline - Upload</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/basic-pipeline-upload/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/basic-pipeline-upload/</guid><description>Upload Pipeline # 이제 우리가 만든 파이프라인을 직접 kubeflow에서 업로드 해 보겠습니다.
파이프라인 업로드는 kubeflow 대시보드 UI를 통해 진행할 수 있습니다. Install Kubeflow 에서 사용한 방법을 이용해 포트포워딩합니다.
kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80 http://localhost:8080에 접속해 대시보드를 열어줍니다.
1. Pipelines 탭 선택 # 2. Upload Pipeline 선택 # 3. Choose file 선택 # 4. 생성된 yaml파일 업로드 # 5. Create # Upload Pipeline Version # 업로드된 파이프라인은 업로드를 통해서 버전을 관리할 수 있습니다.</description></item><item><title>7. Pipeline - Run</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/basic-run/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/basic-run/</guid><description>Run Pipeline # 이제 업로드한 파이프라인을 실행시켜 보겠습니다.
Before Run # 1. Create Experiment # Experiment란 Kubeflow 에서 실행되는 Run을 논리적으로 관리하는 단위입니다.
Kubeflow에서 namespace를 처음 들어오면 생성되어 있는 Experiment가 없습니다. 따라서 파이프라인을 실행하기 전에 미리 Experiment를 생성해두어야 합니다. Experiment이 있다면 Run Pipeline으로 넘어가도 무방합니다.
Experiment는 Create Experiment 버튼을 통해 생성할 수 있습니다.
2. Name 입력 # Experiment로 사용할 이름을 입력합니다.
Run Pipeline # 1. Create Run 선택 # 2. Experiment 선택 # 3.</description></item><item><title>8. Component - InputPath/OutputPath</title><link>https://mlops-for-all.github.io/en/docs/kubeflow/advanced-component/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://mlops-for-all.github.io/en/docs/kubeflow/advanced-component/</guid><description>Complex Outputs # 이번 페이지에서는 Kubeflow Concepts 예시로 나왔던 코드를 컴포넌트로 작성해 보겠습니다.
Component Contents # 아래 코드는 Kubeflow Concepts에서 사용했던 컴포넌트 콘텐츠입니다.
import dill import pandas as pd from sklearn.svm import SVC train_data = pd.read_csv(train_data_path) train_target = pd.read_csv(train_target_path) clf = SVC(kernel=kernel) clf.fit(train_data, train_target) with open(model_path, mode=&amp;#34;wb&amp;#34;) as file_writer: dill.dump(clf, file_writer) Component Wrapper # Define a standalone Python function # 컴포넌트 래퍼에 필요한 Config들과 함께 작성하면 다음과 같이 됩니다.
def train_from_csv( train_data_path: str, train_target_path: str, model_path: str, kernel: str, ): import dill import pandas as pd from sklearn.</description></item></channel></rss>